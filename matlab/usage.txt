In this file, it is explained how to call ASA-BCP in Matlab to solve

                               min f(x)
                          s.t. l <= x <= u

with given vectors l, u and where f(x) is a twice continuously
differentiable function.
-------------------------------------------------------------------------


Usage.
-------------------------------------------------------------------------
X = asa_bcp(OBJ,X0,L,U)
X = asa_bcp(OBJ,X0,L,U,OPTS)
[X,F] = asa_bcp(__)
[X,F,ASA_BCP_INFO] = asa_bcp(__)
-------------------------------------------------------------------------


Input arguments.
-------------------------------------------------------------------------
- OBJ (required) is a structure of function handle elements, where
  OBJ.funct is the objective function,
  OBJ.grad is the gradient of objective function,
  OBJ.hd_prod is the Hessian-vector product (as described below,
  Hessian-vector products can even be approximated by setting the
  parameter 'hd_exact' to false and, in this case, function 'hd_prod' can
  be ignored);
- X0 (required) is the starting point;
- L (required) is the lower bound on the variables;
- U (required) is the upper bound on the variables;
- OPTS (optional) is a structure with algorithm options (see below).

See the example files 'main.m' and 'problem.m' to know input/output
arguments of 'OBJ.funct', 'OBJ.grad' and 'OBJ.hd_prod'.
-------------------------------------------------------------------------


Output arguments.
-------------------------------------------------------------------------
- X is the final solution found by the algorithm;
- F is the objective value at X;
- ASA_BCP_INFO is a structure with the following fields:
    'sup_norm_proj_g' is the sup-norm of X - P[X-G(X)], where
                      P[.] is the projection operator onto [L,U] and G(.)
                      is the gradient of the objective function;
    'it' is the number of iterations;
    'inner_it' is the number of inner conjugate gradient iterations;
    'n_f' is the number of function evaluations;
    'n_g' is the number of gradient evaluations;
    'n_hd' is the number of Hessian-vector products;
    'flag' is an integer describing the exit condition:
           -1 if the problem is infeasible,
            0 if ASA_BCP_INFO.sup_norm_proj_g <= 'eps_opt'
              (default value of 'eps_opt' = 1e-5),
            1 if the directional derivative of the objective function along the
              search direction (in absolute value) <= 'min_gd'
              (default value of 'min_gd' = 1e-15),
            2 if the norm of the projected search direction <= 'min_norm_proj_d'
              (default value of 'min_norm_proj_d' = 1e-9),
            3 if the stepsize <= 'min_stepsize'
              (default value of 'min_stepsize' = 1e-20),
            4 if the number of iterations >= 'max_it'
              (default value of 'max_it' = 1000000),
            5 if the number of function evaluations >= 'max_n_f'
              (default value of 'max_n_f' = 1000000),
            6 if the number of gradient evaluations >= 'max_n_g'
              (default value of 'max_n_g' = 1000000),
            7 if the number of Hessian-vector products >= 'max_n_hd'
              (default value of 'max_n_hd' = 1000000).
            8 if the objective value <= 'min_f'
              (default value of 'min_f' = -1e90),
            9 in case of error when computing the objective function,
           10 in case of error when computing the gradient of the objective function,
           11 in case of error when computing the Hessian-vector product.
-------------------------------------------------------------------------


Options.
-------------------------------------------------------------------------
To change the values of the above parameters 'eps_opt', 'min_gd',
'min_proj_d', 'min_stepsize', 'max_it', 'max_n_f', 'max_n_g', 'max_n_hd'
and 'min_f', use the structure OPTS (it is one of the input arguments of
'asa_bcp', see above), having as field names the names of the parameters
to be changed.
Other parameters that can be changed in the same way are the following:
- 'ls_memory': history length for the computation of the reference value in
               the line search: set 'ls_memory' > 1 for non-monotone line
               search, or 'ls_memory' = 1 for monotone line search
               (default value of 'm' = 100);
- 'z': according to the non-monotone strategy, the objective function must
       be evaluated upon at least once every 'z' iterations
       (default value of 'z' = 20);
- 'hd_exact': true to compute exact Hessian-vector products, false to
              approximate them
              (default value of 'hd_exact' = true);
- 'verbosity': 0 for no prints, 1 for synthetic prints, 2 for detailed prints
               (default value of 'verbosity' = 1).

If 'verbosity' is positive, then the iteration details will be also
reported in file 'iteration_history.txt'.

Finally, if 'hd_exact' is false, the Hessian-vector product H(x)*d is
approximated with [g(x+eps_approx*d)-g(x)]/eps_approx, where g(.) is the
gradient of the objective function and the default value of 'eps_approx'
is 1e-6.
-------------------------------------------------------------------------